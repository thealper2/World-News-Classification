{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras-tcn --no-dependencies --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import time\n",
    "import pickle\n",
    "import tqdm\n",
    "import emoji\n",
    "import io\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from scikitplot.metrics import plot_roc_curve\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, classification_report, confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "from keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tcn import TCN\n",
    "\n",
    "from IPython.display import Markdown\n",
    "\n",
    "def bold(string):\n",
    "    display(Markdown(\"**\" + string + \"**\"))\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/news-texts/news.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stats(data):\n",
    "    bold(\" SHAPE \".center(50, \"#\"))\n",
    "    print(\"ROWS: {}\".format(data.shape[0]))\n",
    "    print(\"COLS: {}\".format(data.shape[1]))\n",
    "    bold(\" TYPES \".center(50, \"#\"))\n",
    "    print(data.dtypes)\n",
    "    bold(\" MISSING VALUES \".center(50, \"#\"))\n",
    "    print(data.isnull().sum())\n",
    "    bold(\" DUPLICATED VALUES \".center(50, \"#\"))\n",
    "    print(\"NUMBER OF DUPLICATED VALUES: {}\".format(data.duplicated().sum()))\n",
    "    #bold(\" DESCRIBE \".center(50, \"#\"))\n",
    "    #print(data.describe().T)\n",
    "    bold(\" MEMORY USAGE \".center(50, \"#\"))\n",
    "    buf = io.StringIO()\n",
    "    data.info(buf=buf)\n",
    "    info = buf.getvalue().split(\"\\n\")[-2].split(\":\")[1].strip()\n",
    "    print(\"Memory Usage: {}\".format(info))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"text\"])\n",
    "df = df.drop_duplicates()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"].value_counts().plot(kind=\"pie\", autopct=\"%.1f%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = Counter(df[\"label\"]).keys()\n",
    "tags_len = Counter(df[\"label\"]).values()\n",
    "tag_df = pd.DataFrame(zip(tags, tags_len), columns=[\"Class\", \"Count\"])\n",
    "tag_df.plot(x=\"Class\", y=\"Count\", kind=\"bar\", legend=False, grid=False, figsize=(15, 5), cmap='viridis')\n",
    "plt.title(\"Class / Count\", fontsize=18)\n",
    "plt.xlabel(\"Class\", fontsize=15)\n",
    "plt.ylabel(\"Count\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Cleaned'] = [token.lower() for token in df['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Cleaned'] = df['Text Cleaned'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Cleaned'] = df['Text Cleaned'].apply(lambda x: re.sub('[0-9]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Cleaned'] = df['Text Cleaned'].apply(lambda x: x.translate(x.maketrans('', '', string.punctuation)))\n",
    "df['Text Cleaned'] = df['Text Cleaned'].apply(lambda x: x.replace('\"', '').replace(\"’\", '').replace(\"'\", '').replace(\"”\", ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Cleaned'] = df['Text Cleaned'].apply(lambda x: re.sub('\\S*@\\S*\\s?', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Cleaned'] = df['Text Cleaned'].apply(lambda x: emoji.replace_emoji(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Cleaned'] = df['Text Cleaned'].apply(lambda x: re.sub('<.*?>', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_words = \"/kaggle/input/smartstoplists/SmartStoplist.txt\"\n",
    "smart_stoplist = []\n",
    "for line in open(smart_words, \"r\"):\n",
    "    if line.strip()[0:1] != \"#\":\n",
    "        for word in line.split():\n",
    "            smart_stoplist.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text Cleaned'] = df['Text Cleaned'].apply(lambda text: ' '.join([word for word in text.split() if word.lower() not in smart_stoplist]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_ngrams(corpus, ngram, n):\n",
    "    vec = CountVectorizer(ngram_range=(ngram,ngram)).fit(corpus)\n",
    "    bow = vec.transform(corpus).sum(axis=0)\n",
    "    words_freq = sorted([(word, bow[0, idx]) for word, idx in vec.vocabulary_.items()], key=lambda x: x[1], reverse=True)[:n]\n",
    "    return words_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ngrams(ngram_df, ngram_name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(data=ngram_df, x=\"Text\", height=\"Count\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(ngram_name)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(ngram_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigrams = count_ngrams(df[\"Text Cleaned\"], 1, 30)\n",
    "top_unigram = pd.DataFrame(unigrams, columns=['Text', \"Count\"])\n",
    "top_unigram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ngrams(top_unigram, \"Unigrams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = count_ngrams(df[\"Text Cleaned\"], 2, 30)\n",
    "top_bigram = pd.DataFrame(bigrams, columns=['Text', \"Count\"])\n",
    "top_bigram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ngrams(top_bigram, \"Bigrams\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = count_ngrams(df[\"Text Cleaned\"], 3, 30)\n",
    "top_trigram = pd.DataFrame(trigrams, columns=['Text', \"Count\"])\n",
    "top_trigram.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ngrams(top_trigram, \"Trigrams\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"Text Cleaned\"]\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000,\n",
    "    filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower = True,\n",
    "    split = \" \")\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenizer = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokenizer = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in X_train_tokenizer + X_test_tokenizer]\n",
    "num_tokens = np.array(num_tokens)\n",
    "maxlen = int(np.mean(num_tokens) + (2 * np.std(num_tokens)))\n",
    "print(maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokenizer = pad_sequences(X_train_tokenizer, maxlen=maxlen)\n",
    "X_test_tokenizer = pad_sequences(X_test_tokenizer, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(tokenizer.word_index) + 1\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "f = open(\"/kaggle/input/glove840b300dtxt/glove.840B.300d.txt\", \"r\", encoding=\"utf-8\")\n",
    "for line in tqdm.tqdm(f):\n",
    "    values = line.split(\" \")\n",
    "    word = values[0]\n",
    "    coefs = np.asarray([float(val) for val in values[1:]])\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((input_dim, 300))\n",
    "for word, i in tqdm.tqdm(tokenizer.word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(shape=(None,), dtype=\"float32\")\n",
    "layer = layers.Embedding(input_dim=input_dim, output_dim=300, weights=[embedding_matrix], input_length=maxlen, trainable=False)(inputs)\n",
    "x = layers.Bidirectional(TCN(64))(x)\n",
    "outputs = layers.Dense(3, activation=\"softmax\")(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"rmsprop\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_accuracy\", patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train_tokenizer, y_train, epochs=25, batch_size=32, validation_split=0.1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test_tokenizer, y_test)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions = model.predict(X_test_tokenizer, verbose=0)\n",
    "model_predictions = [np.argmax(pred) for pred in model_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_precision_score = precision_score(y_test, model_predictions, average=\"weighted\")\n",
    "model_f1_score = f1_score(y_test, model_predictions, average=\"weighted\")\n",
    "model_recall_score = recall_score(y_test, model_predictions, average=\"weighted\")\n",
    "model_accuracy_score = accuracy_score(y_test, model_predictions)\n",
    "\n",
    "print(f\"Precision Score = {model_precision_score * 100:.2f}%\")\n",
    "print(f\"F1 Score = {model_f1_score * 100:.2f}%\")\n",
    "print(f\"Recall Score = {model_recall_score * 100:.2f}%\")\n",
    "print(f\"Accuracy Score = {model_accuracy_score * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, model_predictions)\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm, show_absolute=True, show_normed=True, colorbar=True, class_names=le.classes_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
